{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chocolate is a beloved treat enjoyed by people all over the world.\n",
      "It is made from the seeds of the cocoa tree, which is native to Central and South America.\n"
     ]
    }
   ],
   "source": [
    "text1 = '''\n",
    "<div class=\"container\"><h1>Chocolate is a beloved treat enjoyed by people all over the world. \n",
    "It is made from the seeds of the cocoa tree, which is native to Central and South America.</h1></div>\n",
    "'''\n",
    "\n",
    "document1 = re.sub(\"<[^>]+>\", \"\", text1).strip()\n",
    "sentence1 = sent_tokenize(document1)\n",
    "print(sentence1[0])\n",
    "print(sentence1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat: \n",
      "Chocolate is a beloved treat enjoyed by people all over the world.\n",
      "It is made from the seeds of the cocoa tree, which is native to Central and South America.\n",
      "\n",
      "\n",
      "Hasil: \n",
      "[['chocolate', 'is', 'a', 'beloved', 'treat', 'enjoyed', 'by', 'people', 'all', 'over', 'the', 'world'], ['it', 'is', 'made', 'from', 'the', 'seeds', 'of', 'the', 'cocoa', 'tree', 'which', 'is', 'native', 'to', 'central', 'and', 'south', 'america']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Kalimat: \")\n",
    "print(str(sentence1[0]) + \"\\n\" + str(sentence1[1]) + \"\\n\\n\")\n",
    "\n",
    "sentence2 = []\n",
    "for s in sentence1:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^\\w\\s]','',s)\n",
    "    s = re.sub(r'\\w*\\d\\w*','',s)\n",
    "    if s != None:\n",
    "        sentence2.append(s)\n",
    "    else:\n",
    "        sentence2.append(\".\")\n",
    "word = [word_tokenize(word) for word in sentence2]\n",
    "print(\"Hasil: \\n\" + str(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"you'll\", \"doesn't\", 'then', 'once', \"she's\", 'any', 'doesn', 'can', 'after', \"haven't\", 'couldn', 'mightn', 'yourself', 'as', 'into', 'haven', \"weren't\", 'again', 'herself', 'own', 'll', 'whom', 'isn', 'our', 'but', 'there', 'you', 'needn', 've', 'she', 'i', 'under', 'wouldn', 'has', 'same', 'by', 'which', 'with', 'each', 't', 'some', \"that'll\", 'here', 'did', \"hasn't\", 'd', 'or', 'a', 'ain', \"isn't\", 'more', 're', 'o', 'while', 'hadn', 'do', 'weren', 'an', 'that', 'and', \"it's\", \"hadn't\", 'themselves', 'of', 'her', 'further', 'so', \"won't\", 'your', 'wasn', 's', 'above', 'those', 'because', 'shouldn', 'be', 'up', 'didn', 'not', 'few', 'is', 'between', 'doing', \"couldn't\", 'theirs', 'at', 'these', 'won', 'have', 'having', 'for', 'if', 'he', 'being', 'on', 'the', 'shan', 'what', \"mightn't\", \"you're\", 'about', 'yours', 'am', 'out', 'where', 'y', 'my', 'me', 'to', 'very', \"you'd\", 'from', 'against', 'such', 'will', \"wasn't\", 'him', 'its', 'they', \"shouldn't\", 'myself', \"shan't\", 'than', 'ours', 'mustn', 'just', 'was', \"mustn't\", 'we', \"should've\", 'below', 'only', 'm', 'aren', \"needn't\", 'most', 'itself', 'when', 'before', 'their', 'himself', 'his', 'in', 'nor', 'other', 'too', 'hasn', 'it', 'hers', 'were', 'this', \"aren't\", 'why', 'how', 'ma', 'off', 'during', 'yourselves', \"don't\", \"you've\", 'over', 'them', 'had', 'until', \"wouldn't\", 'down', 'been', 'now', 'who', 'all', 'through', 'does', 'ourselves', 'no', 'both', 'are', 'don', \"didn't\", 'should'}\n"
     ]
    }
   ],
   "source": [
    "english_stop = set(stopwords.words('english'))\n",
    "print(english_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata: \n",
      "[['chocolate', 'is', 'a', 'beloved', 'treat', 'enjoyed', 'by', 'people', 'all', 'over', 'the', 'world'], ['it', 'is', 'made', 'from', 'the', 'seeds', 'of', 'the', 'cocoa', 'tree', 'which', 'is', 'native', 'to', 'central', 'and', 'south', 'america']]\n",
      "\n",
      "\n",
      "Hasil: \n",
      "[['chocolate', 'beloved', 'treat', 'enjoyed', 'people', 'world'], ['made', 'seeds', 'cocoa', 'tree', 'native', 'central', 'south', 'america']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Kata: \\n\" + str(word) + \"\\n\\n\")\n",
    "\n",
    "word2 = [[w for w in words if w not in english_stop] for words in word]\n",
    "print(\"Hasil: \\n\" + str(word2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata: \n",
      "[['chocolate', 'beloved', 'treat', 'enjoyed', 'people', 'world'], ['made', 'seeds', 'cocoa', 'tree', 'native', 'central', 'south', 'america']]\n",
      "\n",
      "\n",
      "Hasil: \n",
      "[['chocol', 'belov', 'treat', 'enjoy', 'peopl', 'world'], ['made', 'seed', 'cocoa', 'tree', 'nativ', 'central', 'south', 'america']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Kata: \\n\" + str(word2) + \"\\n\\n\")\n",
    "\n",
    "word3 = [[PorterStemmer().stem(w) for w in words] for words in word2]\n",
    "print(\"Hasil: \\n\" + str(word3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
